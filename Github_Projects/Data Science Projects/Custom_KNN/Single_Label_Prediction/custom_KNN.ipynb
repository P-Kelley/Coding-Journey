{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showcases a custom KNN classifier for prediction on a iris flower dataset. This has the ability to function identically to sklearns KNN classifer with an added paramter allowing the classifer to assign a custom prediction if there are less neighbors with the same label than the minvote paramter. This may be useful for multilabel classification, or for different distance metrics between labels, allowing for building individual classifers for each label without requiring the classifer to assign a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#KNN classifier from https://combine.se/blog/ml-isnt-all-so-mysterious-implement-your-own-knn-classifier/ with some modifications for allowing a no label prediction and bug fix for kneighbor_labels in predict function . \n",
    "class KNNClassifier:\n",
    "    #minvote is a added parameter that allows you to specify the minimum number of nearest neighbors with that label to vote for that label, otherwise it will vote for label -1, which will correspond to no label\n",
    "    #The default value of 0 makes this act like a standard KNN algorithm\n",
    "    def __init__(self, metric, n_neighbors = 5, minvote = 0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "        self.minvote = minvote\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._X = X.copy().reset_index(drop = True)\n",
    "        self._y = y.copy().astype(int)\n",
    "        self.n_classes = len(set(y))\n",
    "\n",
    "\n",
    "\n",
    "    def kneighbors(self, X, n_neighbors = None):\n",
    "        \"\"\" \n",
    "        X: shape (n_queries, n_features)\n",
    "        return: matrix of indices, shape(n_neighbors, n_queries)\n",
    "        \"\"\"\n",
    "        n_neighbors = n_neighbors if n_neighbors else self.n_neighbors\n",
    "        pairwise_distances = self.metric(self._X, X)\n",
    "        return pairwise_distances.argsort(axis = 0)[:n_neighbors,]\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: shape (n_queries, n_features)\n",
    "        y: shape (n_queries, )\n",
    "        \"\"\"\n",
    "        \n",
    "        kneighbor_indices = self.kneighbors(X)\n",
    "        kneighbor_labels = np.apply_along_axis(\n",
    "                lambda x : self._y.iloc[x],\n",
    "                axis = 0,\n",
    "                arr = kneighbor_indices\n",
    "            )\n",
    "        n_bins = self.n_classes\n",
    "\n",
    "        #This creates 2D array with first array being number of zeros for each class and second array being number of 1s for each class. We will use the largest of the second\n",
    "        label_counts = np.apply_along_axis(\n",
    "            lambda column: np.bincount(column, minlength=n_bins),\n",
    "            axis = 0,\n",
    "            arr=kneighbor_labels\n",
    "        )\n",
    "        \n",
    "    \n",
    "        return np.where(np.max(label_counts, axis = 0) <= self.minvote, -1, label_counts.argmax(axis = 0))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\" \n",
    "        X: shape(n_samples, n_features)\n",
    "        y: shape (n_samples, )\n",
    "        returns score (float)\n",
    "                Accuray of self.preict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        n = len(y)\n",
    "        return (predictions == y).sum() / n\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = pd.read_csv('iris.csv')\n",
    "\n",
    "iris['Name_Code'] = pd.Categorical(iris['Name']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.iloc[:,:4]\n",
    "y = iris.iloc[:,5]\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "mymodel = KNNClassifier(metric = euclidean_distances, n_neighbors=5)\n",
    "mymodel.fit(X_train, y_train)\n",
    "mymodel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy comparision to standard KNN classifer from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
